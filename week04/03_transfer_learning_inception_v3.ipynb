{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer leaning using Inception-v3 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append(\"$HOME/models/research/slim/\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/flowers/flowers_train_00003-of-00005.tfrecord', '../data/flowers/flowers_train_00002-of-00005.tfrecord', '../data/flowers/flowers_train_00001-of-00005.tfrecord', '../data/flowers/flowers_train_00004-of-00005.tfrecord', '../data/flowers/flowers_train_00000-of-00005.tfrecord']\n",
      "['../data/flowers/flowers_validation_00004-of-00005.tfrecord', '../data/flowers/flowers_validation_00001-of-00005.tfrecord', '../data/flowers/flowers_validation_00000-of-00005.tfrecord', '../data/flowers/flowers_validation_00003-of-00005.tfrecord', '../data/flowers/flowers_validation_00002-of-00005.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/flowers/'\n",
    "tfrecord_filenames = os.listdir(data_path)\n",
    "train_data_filenames = [os.path.join(data_path, name) for name in tfrecord_filenames if 'train' in name]\n",
    "validation_data_filenames = [os.path.join(data_path, name) for name in tfrecord_filenames if 'validation' in name]\n",
    "print(train_data_filenames)\n",
    "print(validation_data_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a scalar string `example_proto` into a pair of a scalar string and\n",
    "# a scalar integer, representing an image and its label, respectively.\n",
    "def _parse_function(example_proto):\n",
    "  features = {'image/encoded': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "              'image/format': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "              'image/class/label': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "              'image/height': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "              'image/width': tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "  parsed_features = tf.parse_single_example(example_proto, features)\n",
    "  image = tf.image.decode_jpeg(parsed_features[\"image/encoded\"], channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "  label = tf.cast(parsed_features[\"image/class/label\"], dtype=tf.int32)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocessing(image, label):\n",
    "  \"\"\"data augmentation function for training\n",
    "  augmentation method is borrowed by inception code\n",
    "  \n",
    "  Args:\n",
    "    image (3-rank Tensor): [?, ?, 3] for flower data\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "    \n",
    "  Returns:\n",
    "    image (3-rank Tensor): [299, 299, 3] image transformed\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "  \"\"\"\n",
    "  image = tf.image.resize_image_with_crop_or_pad(image, 299, 299)\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  image = tf.image.random_brightness(image, max_delta=32./255.)\n",
    "  image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "  image = tf.image.random_hue(image, max_delta=0.2)\n",
    "  image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "  image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "  # Finally, rescale to [-1, 1] instead of [0, 1)\n",
    "  image = tf.subtract(image, 0.5)\n",
    "  image = tf.multiply(image, 2.0)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _central_crop(image, label):\n",
    "  \"\"\"data augmentation function for training\n",
    "  augmentation method is borrowed by inception code\n",
    "  \n",
    "  Args:\n",
    "    image (3-rank Tensor): [?, ?, 3] for flower data\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "    \n",
    "  Returns:\n",
    "    image (3-rank Tensor): [299, 299, 3] image transformed\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "  \"\"\"\n",
    "  image = tf.image.central_crop(image, central_fraction=0.875)\n",
    "  image = tf.image.resize_images(image, [299, 299])\n",
    "  # Finally, rescale to [-1, 1] instead of [0, 1)\n",
    "  image = tf.subtract(image, 0.5)\n",
    "  image = tf.multiply(image, 2.0)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 299, 299, 3), (?,)), types: (tf.float32, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 299, 299, 3), (?,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.TFRecordDataset(train_data_filenames)\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "train_dataset = train_dataset.map(_preprocessing)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for validation\n",
    "validation_dataset = tf.data.TFRecordDataset(validation_data_filenames)\n",
    "validation_dataset = validation_dataset.map(_parse_function)\n",
    "validation_dataset = validation_dataset.map(_central_crop)\n",
    "validation_dataset = validation_dataset.shuffle(buffer_size = 10000)\n",
    "validation_dataset = validation_dataset.batch(batch_size = batch_size)\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Iterator.from_string_handle의 output_shapes는 default = None이지만 꼭 값을 넣는 게 좋음\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "inputs, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Inception-v3 graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)\n",
    "with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "  logits, _ = inception_v3.inception_v3(inputs, num_classes=5, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"InceptionV3/Logits/SpatialSqueeze:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_one_hot = tf.one_hot(y, depth=10)\n",
    "#cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=y_pred)\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "l2_regualrization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "with tf.name_scope('total_loss'):\n",
    "  total_loss = cross_entropy + l2_regualrization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization update\n",
    "batchnorm_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "# Add dependency to compute batchnorm_updates.\n",
    "with tf.control_dependencies(batchnorm_update_ops):\n",
    "  train_step = tf.train.RMSPropOptimizer(1e-4).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  writer = tf.summary.FileWriter(\"./graphs/code03_transfer_learning_inception_v3\", sess.graph)\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Inception-v3 checkpoint: \n",
    "\n",
    "```\n",
    "$ CHECKPOINT_DIR='checkpoints'\n",
    "$ mkdir ${CHECKPOINT_DIR}\n",
    "$ wget http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\n",
    "$ tar -xvf inception_v3_2016_08_28.tar.gz\n",
    "$ mv inception_v3_2016_08_28.tar.gz ${CHECKPOINT_DIR}\n",
    "$ rm inception_v3_2016_08_28.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Inception_v3 weights using `tf.saver.restore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../checkpoints/inception_v3.ckpt\n",
      "epochs: 0, step: 0, loss: 2.00347, (0.38 examples/sec; 85.002 sec/batch)\n",
      "epochs: 0, step: 1, loss: 1.96022, (0.86 examples/sec; 37.271 sec/batch)\n",
      "epochs: 0, step: 2, loss: 2.0151, (0.94 examples/sec; 34.137 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables()[:-8])\n",
    "\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# use saver object to load variables from the saved model\n",
    "saver.restore(sess, \"../checkpoints/inception_v3.ckpt\")\n",
    "\n",
    "# train_iterator\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "# Train\n",
    "max_epochs = 1\n",
    "step = 0\n",
    "for epochs in range(max_epochs):\n",
    "  sess.run(train_iterator.initializer)\n",
    "\n",
    "  while True:\n",
    "    try:\n",
    "      start_time = time.time()\n",
    "      _, loss = sess.run([train_step, total_loss],\n",
    "                         feed_dict={handle: train_handle,\n",
    "                                    is_training: True})\n",
    "      if step % 1 == 0:\n",
    "        duration = time.time() - start_time\n",
    "        examples_per_sec = batch_size / float(duration)\n",
    "        print(\"epochs: {}, step: {}, loss: {:g}, ({:.2f} examples/sec; {:.3f} sec/batch)\".format(epochs, step, loss, examples_per_sec, duration))\n",
    "        \n",
    "      #if step % 200 == 0:\n",
    "      #  # summary\n",
    "      #  summary_str = sess.run(summary_op, feed_dict={handle: train_handle, is_training: False})\n",
    "      #  train_writer.add_summary(summary_str, global_step=step)\n",
    "        \n",
    "      step += 1\n",
    "      #if step > 100:\n",
    "      #  break\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "\n",
    "train_writer.close()\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
