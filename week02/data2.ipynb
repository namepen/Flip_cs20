{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "np.random.seed(219)\n",
    "tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data[:50]\n",
    "train_labels = train_labels[:50]\n",
    "train_data = train_data / 255.\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data[:50]\n",
    "test_labels = test_labels[:50]\n",
    "test_data = test_data / 255.\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n",
      "<BatchDataset shapes: ((?, 28, 28), (?,)), types: (tf.float64, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "#train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000, seed=None, reshuffle_each_iteration=False)\n",
    "train_dataset = train_dataset.repeat(count=2)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 10000)\n",
    "test_dataset = test_dataset.repeat(count=2)\n",
    "test_dataset = test_dataset.batch(batch_size = batch_size)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `from_string_handle`\n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "from_string_handle(\n",
    "    string_handle,\n",
    "    output_types,\n",
    "    output_shapes=None,\n",
    "    output_classes=None\n",
    ")\n",
    "```\n",
    "\n",
    "Creates a new, uninitialized Iterator based on the given handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 `make_one_shot_iterator()`\n",
    "\n",
    "Creates an Iterator for enumerating the elements of this dataset.\n",
    "* Note: The returned iterator will be initialized automatically. A \"one-shot\" iterator does not currently support re-initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, train_iterator.output_types)\n",
    "\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  labels:\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "step: 1  labels:\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "step: 2  labels:\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "step: 3  labels:\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "step: 4  labels:\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "step: 5  labels:\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "step: 6  labels:\n",
      "[5 8 3 3]\n",
      "[1 3 5 1]\n",
      "End of dataset\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "\n",
    "train_iterator_handle = sess.run(train_iterator.string_handle())\n",
    "test_iterator_handle = sess.run(test_iterator.string_handle())\n",
    "\n",
    "# Train\n",
    "max_epochs = 2\n",
    "step = 0\n",
    "for epoch in range(max_epochs):\n",
    "  #sess.run(iterator.initializer) 할 필요 없음\n",
    "\n",
    "  try:\n",
    "    while True:\n",
    "      train_labels_ = sess.run(y, feed_dict={handle: train_iterator_handle})\n",
    "      test_labels_ = sess.run(y, feed_dict={handle: test_iterator_handle})\n",
    " \n",
    "      print(\"step: %d  labels:\" % step)\n",
    "      print(train_labels_)\n",
    "      print(test_labels_)\n",
    "        \n",
    "      step += 1\n",
    "\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    print(\"End of dataset\")  # ==> \"End of dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 `make_initializable_iterator()`\n",
    "\n",
    "```python\n",
    "make_initializable_iterator(shared_name=None)\n",
    "```\n",
    "\n",
    "Creates an Iterator for enumerating the elements of this dataset.\n",
    "\n",
    "사용법\n",
    "```python\n",
    "dataset = ...\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "# ...\n",
    "sess.run(iterator.initializer)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, train_iterator.output_types, train_iterator.output_shapes)\n",
    "\n",
    "x, y = iterator.get_next()\n",
    "x = tf.cast(x, dtype = tf.float32)\n",
    "y = tf.cast(y, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  labels:\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "step: 1  labels:\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "step: 2  labels:\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "step: 3  labels:\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "step: 4  labels:\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "step: 5  labels:\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "step: 6  labels:\n",
      "[5 8 3 3]\n",
      "[1 3 5 1]\n",
      "End of dataset\n",
      "step: 7  labels:\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "step: 8  labels:\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "step: 9  labels:\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "step: 10  labels:\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "step: 11  labels:\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "step: 12  labels:\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "step: 13  labels:\n",
      "[5 8 3 3]\n",
      "[1 3 5 1]\n",
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "\n",
    "train_iterator_handle = sess.run(train_iterator.string_handle())\n",
    "test_iterator_handle = sess.run(test_iterator.string_handle())\n",
    "\n",
    "train_initializer = iterator.make_initializer(train_dataset)\n",
    "test_initializer = iterator.make_initializer(test_dataset)\n",
    "\n",
    "# Train\n",
    "max_epochs = 2\n",
    "step = 0\n",
    "for epoch in range(max_epochs):\n",
    "  sess.run(train_iterator.initializer)\n",
    "  sess.run(test_iterator.initializer)\n",
    "  \n",
    "  try:\n",
    "    while True:\n",
    "      train_labels_ = sess.run(y, feed_dict={handle: train_iterator_handle})\n",
    "      test_labels_ = sess.run(y, feed_dict={handle: test_iterator_handle})\n",
    " \n",
    "      print(\"step: %d  labels:\" % step)\n",
    "      print(train_labels_)\n",
    "      print(test_labels_)\n",
    "        \n",
    "      step += 1\n",
    "\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    print(\"End of dataset\")  # ==> \"End of dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `from_structure`\n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "from_structure(\n",
    "    output_types,\n",
    "    output_shapes=None,\n",
    "    shared_name=None,\n",
    "    output_classes=None\n",
    ")\n",
    "```\n",
    "\n",
    "Creates a new, uninitialized Iterator with the given structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 `make_one_shot_iterator()`\n",
    "\n",
    "Creates an Iterator for enumerating the elements of this dataset.\n",
    "* Note: The returned iterator will be initialized automatically. A \"one-shot\" iterator does not currently support re-initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[5 8 3 3]\n",
      "test\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "[1 3 5 1]\n",
      "train\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[5 8 3 3]\n",
      "test\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "[1 3 5 1]\n"
     ]
    }
   ],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_iterator.output_types)\n",
    "\n",
    "train_initializer = iterator.make_initializer(train_dataset)\n",
    "test_initializer = iterator.make_initializer(test_dataset)\n",
    "\n",
    "x, y = iterator.get_next()\n",
    "\n",
    "sess = tf.Session(config=sess_config)\n",
    "# Train for `num_epochs`, where for each epoch, we first iterate over\n",
    "# dataset_range, and then iterate over dataset_evens.\n",
    "for _ in range(2):\n",
    "  # Initialize the iterator to `dataset_range`\n",
    "  print('train')\n",
    "  sess.run(train_initializer)\n",
    "  while True:\n",
    "    try:\n",
    "      y_ = sess.run(y)\n",
    "      print(y_)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      break\n",
    "      \n",
    "  print('test')\n",
    "  sess.run(test_initializer)\n",
    "  while True:\n",
    "    try:\n",
    "      y_ = sess.run(y)\n",
    "      print(y_)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `make_initializable_iterator()`\n",
    "\n",
    "```python\n",
    "make_initializable_iterator(shared_name=None)\n",
    "```\n",
    "\n",
    "Creates an Iterator for enumerating the elements of this dataset.\n",
    "\n",
    "사용법\n",
    "```python\n",
    "dataset = ...\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "# ...\n",
    "sess.run(iterator.initializer)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[5 8 3 3]\n",
      "test\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "[1 3 5 1]\n",
      "train\n",
      "[7 9 2 9 9 6 1 1 8 6 6 8 6 9 3 2]\n",
      "[0 4 9 7 2 3 3 0 5 1 0 7 1 9 0 4]\n",
      "[1 5 3 9 1 6 7 5 3 4 4 1 8 2 5 8]\n",
      "[3 3 7 9 2 9 9 6 1 1 8 6 6 8 6 9]\n",
      "[3 2 0 4 9 7 2 3 3 0 5 1 0 7 1 9]\n",
      "[0 4 1 5 3 9 1 6 7 5 3 4 4 1 8 2]\n",
      "[5 8 3 3]\n",
      "test\n",
      "[1 9 5 7 7 3 0 4 9 6 3 6 4 1 0 4]\n",
      "[4 3 1 9 1 7 2 2 5 0 0 0 5 7 6 7]\n",
      "[5 4 2 2 1 2 1 9 1 9 3 4 7 1 1 4]\n",
      "[4 4 4 4 1 0 1 3 0 7 4 6 9 1 7 4]\n",
      "[1 7 9 2 6 9 7 4 9 2 1 5 2 5 3 9]\n",
      "[3 6 4 1 0 7 2 4 4 5 0 2 4 0 1 7]\n",
      "[1 3 5 1]\n"
     ]
    }
   ],
   "source": [
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_iterator.output_types)\n",
    "\n",
    "train_initializer = iterator.make_initializer(train_dataset)\n",
    "test_initializer = iterator.make_initializer(test_dataset)\n",
    "\n",
    "x, y = iterator.get_next()\n",
    "\n",
    "sess = tf.Session(config=sess_config)\n",
    "# Train for `num_epochs`, where for each epoch, we first iterate over\n",
    "# dataset_range, and then iterate over dataset_evens.\n",
    "for _ in range(2):\n",
    "  # Initialize the iterator to `dataset_range`\n",
    "  print('train')\n",
    "  sess.run(train_initializer)\n",
    "  while True:\n",
    "    try:\n",
    "      y_ = sess.run(y)\n",
    "      print(y_)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      break\n",
    "      \n",
    "  print('test')\n",
    "  sess.run(test_initializer)\n",
    "  while True:\n",
    "    try:\n",
    "      y_ = sess.run(y)\n",
    "      print(y_)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
