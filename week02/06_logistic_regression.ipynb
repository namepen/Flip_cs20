{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with MNIST\n",
    "\n",
    "* [참고: TensorFlow.org](https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "* [소스: mnist_softmax.py in verion 1.4](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_softmax.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A very simple MNIST classifier.\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/beginners in version 1.4\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "\n",
    "np.random.seed(219)\n",
    "tf.set_random_seed(219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape(-1, 784)\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape(-1, 784)\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = 1000\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n",
    "\n",
    "### Create placeholders for inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기를 직접 채워 넣으시면 됩니다.\n",
    "# x, y는 배치 데이터를 받을 수 있는 placeholder\n",
    "# x: inputs\n",
    "x = tf.placeholder(tf.float32, name='x', shape=[None, 784])\n",
    "# y: labels\n",
    "y = tf.placeholder(tf.int32, name='y', shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기를 직접 채워 넣으시면 됩니다.\n",
    "# create Variables using `get_variable`\n",
    "W = tf.get_variable(name='weight', shape=[784, 10],\n",
    "                    initializer=tf.random_normal_initializer())\n",
    "b = tf.get_variable(name='bias', shape=[10],\n",
    "                    initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model: $y = Wx + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기를 직접 채워 넣으시면 됩니다.\n",
    "y_pred = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function\n",
    "\n",
    "* [`tf.nn.softmax_cross_entropy_with_logits_v2`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)\n",
    "* [`tf.losses.softmax_cross_entropy`](https://www.tensorflow.org/api_docs/python/tf/losses/softmax_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처: TensorFlow 공식 문서\n",
    "# The raw formulation of cross-entropy,\n",
    "#\n",
    "#   tf.reduce_mean(-tf.reduce_sum(y * tf.log(tf.nn.softmax(y_pred)),\n",
    "#                                 reduction_indices=[1]))\n",
    "#\n",
    "# can be numerically unstable.\n",
    "#\n",
    "# So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "# outputs of 'y', and then average across the batch.\n",
    "y_one_hot = tf.one_hot(y, depth=10)\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot,\n",
    "                                                logits=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Session()` and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "num_batches_per_epoch = int(len(train_data) / batch_size)\n",
    "print(\"num_batches_per_epoch {}\".format(num_batches_per_epoch))\n",
    "\n",
    "max_epochs = 1 # Train for only ten epochs\n",
    "losses = []\n",
    "start_time = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "  # 여기를 직접 채워 넣으시면 됩니다.\n",
    "  batch_index = np.random.permutation(len(train_data))\n",
    "  for step in range(num_batches_per_epoch):\n",
    "    # 여기를 직접 채워 넣으시면 됩니다.\n",
    "    # train_data, train_labels의 인덱스를 잘 설정해보세요.\n",
    "    batch_xs = train_data[step*batch_size:(step+1)*batch_size]\n",
    "    batch_ys = train_labels[step*batch_size:(step+1)*batch_size]\n",
    "    _, loss = sess.run([train_op, cross_entropy],\n",
    "                       feed_dict={x: batch_xs, y: batch_ys})\n",
    "    losses.append(loss)\n",
    "  \n",
    "    if step % 100 == 0:\n",
    "      print(\"step: {}, loss: {}\".format(step, loss))\n",
    "    \n",
    "print('training done!')\n",
    "print(\"Elapsed time: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model\n",
    "\n",
    "* test accuracy: 0.8893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y, tf.int64))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: test_data,\n",
    "                                    y: test_labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "batch_xs = test_data[batch_index]\n",
    "y_pred_ = sess.run(y_pred, feed_dict={x: batch_xs})\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  p.set_title(\"y_pred: {}\".format(np.argmax(py)))\n",
    "  p.imshow(px.reshape(28, 28), cmap='gray')\n",
    "  p.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
