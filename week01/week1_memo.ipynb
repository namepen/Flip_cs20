{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow의 장점\n",
    "\n",
    "* Python API\n",
    "* Portability: deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API\n",
    "* Flexibility: from Raspberry Pi, Android, Windows, iOS, Linux to server farms\n",
    "* Visualization (TensorBoard is da bomb)\n",
    "* Save and restore models, graphs\n",
    "* Auto-differentiation autodiff (no more taking derivatives by hand. Yay)\n",
    "* Large community (~300k commits, ~85k repositories)\n",
    "* Awesome projects already using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level APIs on top of TensorFlow\n",
    "\n",
    "텐서플로에는 여러가지의 high level API를 제공하고 있다. 인기있는 API로는 keras, TFLearn, Sonnet 등이 있다. High level API는 하고자 하는 실험을 간단하게 만들어 줄수 있으며, 복잡한 모델을 단 몇 줄의 코드로 만들 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow의 동작방식\n",
    "\n",
    "먼저 텐서플로의 그래프 계산에 대해 이해할 필요가 있다. 텐서플로는 그래프라는 독특한 방식을 이용하는데, 모든 텐서플로 프로그램은 두가지 방식으로 구성된다.\n",
    "\n",
    "1. 그래프를 모은다.(assemble a graph)\n",
    "2. 세션을 이용해서, 그래프 안에 있는 연산을 실행한다.\n",
    "\n",
    "*단, eager mode에서는 이러한 방식이 바뀌게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서(Tensor)란 무엇일까??\n",
    "\n",
    "텐서란 간단하게 말하면, 데이터 자체라고 생각하면된다. \n",
    "텐서는 텐서플로 안에서 n차원의 array 형태로 구현되어있다. 이 텐서에 데이터를 넣고(input), 그래프를 통과시키면서 연산을 하게된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.add(3,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "위 코드를 살펴보면 a는 3,5를 더한 값인 8이 아니고, 3,5를 더하는 연산이라고 정의되어 있다.\n",
    "그렇다면, a의 값을 얻기 위해서는 어떻게 해야할까? \n",
    "Session을 생성해야한다. session을 생성한 후에, 변수를 할당하고, 그래프를 통과시켜 a의 값을 구하게(fetch)된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#세션을 열고 닫는 과정은 다른 방식의 코드로 작성할 수 있다.\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session Object에 대해 슬라이드에서는 다음과 같이 정의한다. Operation 객체를 실행하고, 텐서를 구하는 환경이라고 말하고 있다.\n",
    "\n",
    "'A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated.'\n",
    "\n",
    "'Session will also allocate memory to store the current values of variables.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#몇 가지 그래프를 더 만들어 보는 code\n",
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x,y)\n",
    "op2 = tf.multiply(x,y)\n",
    "op3 = tf.pow(op1,op2)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(op3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useless 연산은 Session에서 실행되지 않으므로, 계산 graph만 저장된다.\n",
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(pow_op) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Session run의 fetches 값은 arrary 형태로 여러개를 넣을 수도 있다.\n",
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "with tf.Session() as sess:\n",
    "    z, not_useless = sess.run([pow_op, useless])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장치 할당에 대한 자세한 사항은 다음 사이트에서 확인 할 수 있다.\n",
    "[Tensorflow Document](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/how_tos/using_gpu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여러 그래프 연산이 있을 경우, 다른 CPU나 GPU로 병렬 연산 처리가 가능하다. 그래프를 연산 장치 별로 할당하는 방법은 다음과 같다.\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
    "c = tf.multiply(a,b)\n",
    "\n",
    "# log_device_placement을 True로 설정하여 세션을 만듭니다.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# 실행 op\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAPH\n",
    "\n",
    "여러 개의 세션을 돌리기 위해서는 여러 graph가 필요하다. 기본적으로 default 그래프가 주어지고 이를 사용하게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#default 그래프가 아닌 새로운 그래프를 추가하려면 다음과 같이 작성하면 된다.\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.add(3, 5)\n",
    "sess = tf.Session(graph=g)\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default graph를 정의하려면 다음과 같이 정의한다.\n",
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#유저가 만든 그래프와 default 그래프를 섞어서 쓰면 안된다.\n",
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "#add ops to the default graph\n",
    "with g1.as_default():\n",
    "    a = tf.constant(3)\n",
    "    \n",
    "#add ops to the user created graph\n",
    "with g2.as_default():\n",
    "    b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프를 사용하는 이유?\n",
    "\n",
    "1. Save computation. Only run subgraphs that lead to the values you want to fetch.\n",
    "2. Break computation into small, differential pieces to facilitate auto-differentiation\n",
    "3. Facilitate distributed computation, spread the work across multiple CPUs, GPUs, TPUs, or other devices\n",
    "4. Many common machine learning models are taught and visualized as directed graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
