{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- translation 문제를 해결하기 위한 방법\n",
    "- 예전에는 rule-base 기반의 단순하게 pair를 맞추어 번역을 실시\n",
    "- 그 후 probability를 활용한 SMT 방법이 대두되었다. \n",
    "    argmax(P(y|x))\n",
    "- 이를 bayes Rule를 이용하여 두개의 components로 분리하였다\n",
    "    1. P(x|y) -> Transloation Model\n",
    "    2. P(y) -> Language Model\n",
    "- P(x|y)를 어떻게 학습시킬 것인가??\n",
    "    1. need large amount of parallel data\n",
    "    2. break i t down P(x, a|y), a 는 alignment\n",
    "- 매우 복잡하다. 많은 feature engineering 이 필요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2014년 singel neural network를 이용하는 NMT 방법이 등장\n",
    "- 두개의 RNN을 포함하는 이 neural network architecture를 sequence to sqeuence라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder -> input을 벡터로 변형하는 과정\n",
    "\n",
    "test하는 경우, input + start token을 넣어줌.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### machine Translation\n",
    "\n",
    "Machine Translation(MT)는 하나의 언어로 쓰여진 문장 X를 다른 언어의 문장인 Y로 번역하는 과정이다.\n",
    "\n",
    "기계 번역 연구는 1950년도 부터 시작되었으며, 초장기에는 Russan -> English에서 많이 사용되었다. \n",
    "\n",
    "1990s - 2010s : statistial Machine Translation\n",
    "\n",
    "핵심 아이디어 : data에서 확률 모델(probabilistic model)을 학습하자.\n",
    "Bayes Rule을 이용하여 두개의 요소로 분리하자.\n",
    "\n",
    "p(x|y)를 어떻게 학습할까? -> 데이터 쌍(parallel data)를 많이 수집한다.\n",
    "\n",
    "현재는 alignment를 구하는 것으로 대체\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- end to end training\n",
    "\n",
    "- distributed representations share strength\n",
    "\n",
    "- better exploitation of context\n",
    "\n",
    "- more fluent text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### google's multilingual NMT system\n",
    "\n",
    "- simplicity = single model\n",
    "- low resource language\n",
    "- zero - shot translation, meaning that the model acn inclusively translate for the language paris it has never seen during training time.\n",
    "\n",
    "- zero shot learning이란?\n",
    " 이를 테면 이런 식이다. 구글번역이 영어-한국어, 영어 일본어 언어쌍을 각각 번역할 수 있는 지식을 갖추고 있을 경우 한국어-일본어 언어쌍에 대해서도 별도 머신러닝을 통한 학습과정을 거치지 않아도 번역이 가능해진다는 설명이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention mechanism\n",
    "\n",
    "- seq2seq의 문제점? 마지막 encorder에서 정보가 집약되어 bottle neck 현상이 발생한다(this needs to capture all information about the source sentence.) -> attention을 사용해서 bottle neck problem을 해결하자\n",
    "\n",
    "- Core idea : decoder의 각 step에서 source sequence의 특정부분(particular part)에 집중해보자. 같은 부분을 담당하는 decoder의 hidden state와 encoder의 hidden state는 비슷할 것이다라는 아이디어.\n",
    "\n",
    "- 진행 방식\n",
    "    1. decoder의 i번째 hidden state와 encoder의 각각 hidden state과 행렬 곱(dot product)를 구한다\n",
    "    2. dot product한 결과를 softmax를 이용하여 score을 확률 분포(probability distribution)로 변환한다.\n",
    "    3. attention distribution을 이용하여 weight sum을 구한다. \n",
    "    4. attention output을 이용하여 encoder에서 y_1을 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e - whole sentence, \n",
    "bayes rule을 이용하여 확률 식을 변환,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 사이트\n",
    "\n",
    "oxford 강의 자료, https://github.com/oxford-cs-deepnlp-2017/lectures\n",
    "gloVe: global vector for word Representation, https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "zero shot learning, http://m.zdnet.co.kr/news_view.asp?article_id=20170302163740\n",
    "\n",
    "attention mechanism, https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/10/06/attention/\n",
    "http://freesearch.pe.kr/archives/4724\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
